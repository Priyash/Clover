2021-07-20 00:00:32,119 INFO [1076] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 24144 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:00:32,158 DEBUG [1115] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:00:32,158 INFO [1115] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:00:43,485 INFO [12442] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.965 seconds (JVM running for 12.92)
2021-07-20 00:02:00,007 INFO [88964] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:02:00,009 INFO [88966] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:02:21,959 ERROR [110916] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:88] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productimage <-> com.clover.storage.model.ProductImage]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:44)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:14)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:81)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 00:04:00,007 INFO [208964] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:04:00,007 INFO [208964] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:04:57,578 ERROR [266535] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:88] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 1.0 failed 1 times, most recent failure: Lost task 19.0 in stage 1.0 (TID 46, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productimage <-> com.clover.storage.model.ProductImage]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:44)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:14)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:81)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 00:24:55,685 INFO [985 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 23512 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:24:55,689 DEBUG [989 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:24:55,689 INFO [989 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:25:06,815 INFO [12115] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.651 seconds (JVM running for 12.575)
2021-07-20 00:26:00,011 INFO [65311] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:26:00,012 INFO [65312] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:26:11,540 ERROR [76840] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:88] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productimage <-> com.clover.storage.model.ProductImage]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:44)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:14)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:81)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 00:28:12,102 INFO [1029] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 9256 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:28:12,106 DEBUG [1033] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:28:12,106 INFO [1033] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:28:24,674 INFO [13601] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 13.137 seconds (JVM running for 14.055)
2021-07-20 00:30:00,015 INFO [108942] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:30:00,015 INFO [108942] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:30:04,009 ERROR [112936] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:88] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Couldn't find table product_tbl_test or keyspace product_db_test - Found similar keyspaces and tables:
product_keyspace.product_table
	at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:358)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:50)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:137)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:263)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:81)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 00:35:41,330 INFO [980 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 25572 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:35:41,334 DEBUG [984 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:35:41,334 INFO [984 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:36:49,684 INFO [1081] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 24456 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:36:49,687 DEBUG [1084] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:36:49,688 INFO [1085] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:37:02,909 INFO [14306] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 13.817 seconds (JVM running for 14.766)
2021-07-20 00:38:00,016 INFO [71413] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:38:00,016 INFO [71413] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:38:15,044 INFO [86441] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:82] [Scheduler]Spark streaming context product size: 0
2021-07-20 00:40:00,014 INFO [191411] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:40:00,014 INFO [191411] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:40:06,904 ERROR [198301] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:88] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Failed to open native connection to Cassandra at {127.0.0.1}:9042
	at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:168)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$8.apply(CassandraConnector.scala:154)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$8.apply(CassandraConnector.scala:154)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:79)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.rdd.partitioner.dht.TokenFactory$.forSystemLocalPartitioner(TokenFactory.scala:98)
	at com.datastax.spark.connector.rdd.partitioner.SplitSizeEstimator$class.tokenFactory(SplitSizeEstimator.scala:9)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tokenFactory$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tokenFactory(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.partitioner.SplitSizeEstimator$class.estimateDataSize(SplitSizeEstimator.scala:12)
	at com.datastax.spark.connector.rdd.partitioner.SplitSizeEstimator$class.estimateSplitCount(SplitSizeEstimator.scala:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.estimateSplitCount(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$1.apply$mcI$sp(CassandraTableScanRDD.scala:227)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$1.apply(CassandraTableScanRDD.scala:227)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$1.apply(CassandraTableScanRDD.scala:227)
	at scala.Option.getOrElse(Option.scala:121)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.partitionGenerator$lzycompute(CassandraTableScanRDD.scala:227)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.partitionGenerator(CassandraTableScanRDD.scala:223)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:272)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:81)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.DriverException: Connection thread interrupted))
	at com.datastax.driver.core.ControlConnection.reconnectInternal(ControlConnection.java:270)
	at com.datastax.driver.core.ControlConnection.connect(ControlConnection.java:109)
	at com.datastax.driver.core.Cluster$Manager.negotiateProtocolVersionAndConnect(Cluster.java:1813)
	at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1726)
	at com.datastax.driver.core.Cluster.getMetadata(Cluster.java:462)
	at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:161)
	... 49 common frames omitted
2021-07-20 00:43:36,751 INFO [1030] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 22296 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:43:36,754 DEBUG [1033] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:43:36,755 INFO [1034] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:43:47,929 INFO [12208] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.726 seconds (JVM running for 12.687)
2021-07-20 00:44:00,001 INFO [24280] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:44:00,002 INFO [24281] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:44:11,531 INFO [35810] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:82] [Scheduler]Spark streaming context product size: 0
2021-07-20 00:44:57,805 INFO [999 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 24284 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:44:57,809 DEBUG [1003] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:44:57,809 INFO [1003] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:45:09,082 INFO [12276] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.817 seconds (JVM running for 12.806)
2021-07-20 00:46:00,010 INFO [63204] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:46:00,010 INFO [63204] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:46:40,230 INFO [103424] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:82] [Scheduler]Spark streaming context product size: 0
2021-07-20 00:46:57,600 INFO [988 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 17984 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:46:57,604 DEBUG [992 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:46:57,604 INFO [992 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:47:08,811 INFO [12199] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.746 seconds (JVM running for 12.646)
2021-07-20 00:48:00,014 INFO [63402] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:48:00,015 INFO [63403] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:49:16,917 INFO [140305] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:82] [Scheduler]Spark streaming context product size: 0
2021-07-20 00:52:43,454 INFO [998 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 22152 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:52:43,458 DEBUG [1002] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:52:43,458 INFO [1002] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:52:54,553 INFO [12097] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.645 seconds (JVM running for 12.575)
2021-07-20 00:54:00,008 INFO [77552] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron job started...
2021-07-20 00:54:00,009 INFO [77553] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:48] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 00:55:32,920 INFO [170464] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:76] [Scheduler]Spark streaming context product size: 0
2021-07-20 00:56:02,962 INFO [976 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20316 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 00:56:02,965 DEBUG [979 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 00:56:02,965 INFO [979 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 00:56:14,126 INFO [12140] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.705 seconds (JVM running for 12.607)
2021-07-20 00:58:00,007 INFO [118021] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 00:58:00,007 INFO [118021] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:03:13,630 INFO [431644] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:69] [Scheduler]Spark streaming context product size: 0
2021-07-20 01:04:00,014 INFO [478028] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:04:00,014 INFO [478028] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:04:07,358 INFO [485372] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:69] [Scheduler]Spark streaming context product size: 0
2021-07-20 01:04:58,192 INFO [987 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 22328 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:04:58,195 DEBUG [990 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:04:58,195 INFO [990 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:07:57,736 INFO [989 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 13224 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:07:57,739 DEBUG [992 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:07:57,740 INFO [993 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:08:09,045 INFO [12298] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.864 seconds (JVM running for 12.786)
2021-07-20 01:10:00,010 INFO [123263] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:10:00,011 INFO [123264] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:10:53,084 INFO [176337] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:69] [Scheduler]Spark streaming context product size: 0
2021-07-20 01:11:11,426 INFO [1009] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 21000 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:11:11,430 DEBUG [1013] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:11:11,431 INFO [1014] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:11:22,697 INFO [12280] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.831 seconds (JVM running for 12.721)
2021-07-20 01:12:00,009 INFO [49592] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:12:00,010 INFO [49593] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:19:19,322 INFO [488905] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:69] [Scheduler]Spark streaming context product size: 0
2021-07-20 01:21:59,402 INFO [910 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 24884 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:21:59,407 DEBUG [915 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:21:59,408 INFO [916 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:22:10,675 INFO [12183] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.723 seconds (JVM running for 13.286)
2021-07-20 01:24:00,007 INFO [121515] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:24:00,008 INFO [121516] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:25:34,590 INFO [216098] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:69] [Scheduler]Spark streaming context product size: 0
2021-07-20 01:25:38,635 INFO [1030] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 14936 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:25:38,638 DEBUG [1033] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:25:38,638 INFO [1033] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:25:57,807 INFO [20202] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 19.702 seconds (JVM running for 20.877)
2021-07-20 01:26:00,007 INFO [22402] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:26:00,008 INFO [22403] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:27:41,306 ERROR [123701] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:75] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Failed to open native connection to Cassandra at {127.0.0.1}:9042
	at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:168)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$8.apply(CassandraConnector.scala:154)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$8.apply(CassandraConnector.scala:154)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:79)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.withClusterDo(CassandraConnector.scala:122)
	at com.datastax.spark.connector.cql.Schema$.fromCassandra(Schema.scala:332)
	at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:352)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:50)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:137)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:263)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.DriverException: Connection thread interrupted))
	at com.datastax.driver.core.ControlConnection.reconnectInternal(ControlConnection.java:270)
	at com.datastax.driver.core.ControlConnection.connect(ControlConnection.java:109)
	at com.datastax.driver.core.Cluster$Manager.negotiateProtocolVersionAndConnect(Cluster.java:1813)
	at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1726)
	at com.datastax.driver.core.Cluster.getMetadata(Cluster.java:462)
	at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:161)
	... 49 common frames omitted
2021-07-20 01:27:47,297 INFO [1019] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 9536 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:27:47,302 DEBUG [1024] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:27:47,302 INFO [1024] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:27:58,611 INFO [12333] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.846 seconds (JVM running for 12.814)
2021-07-20 01:28:00,009 INFO [13731] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:28:00,010 INFO [13732] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:29:07,993 ERROR [81715] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:75] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Failed to open native connection to Cassandra at {127.0.0.1}:9042
	at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:168)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$8.apply(CassandraConnector.scala:154)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$8.apply(CassandraConnector.scala:154)
	at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:32)
	at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
	at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
	at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:79)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.withClusterDo(CassandraConnector.scala:122)
	at com.datastax.spark.connector.cql.Schema$.fromCassandra(Schema.scala:332)
	at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:352)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:50)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:137)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:263)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.DriverException: Connection thread interrupted))
	at com.datastax.driver.core.ControlConnection.reconnectInternal(ControlConnection.java:270)
	at com.datastax.driver.core.ControlConnection.connect(ControlConnection.java:109)
	at com.datastax.driver.core.Cluster$Manager.negotiateProtocolVersionAndConnect(Cluster.java:1813)
	at com.datastax.driver.core.Cluster$Manager.init(Cluster.java:1726)
	at com.datastax.driver.core.Cluster.getMetadata(Cluster.java:462)
	at com.datastax.spark.connector.cql.CassandraConnector$.com$datastax$spark$connector$cql$CassandraConnector$$createSession(CassandraConnector.scala:161)
	... 49 common frames omitted
2021-07-20 01:29:12,802 INFO [986 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 4260 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:29:12,805 DEBUG [989 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:29:12,806 INFO [990 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 01:29:24,011 INFO [12195] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.746 seconds (JVM running for 12.697)
2021-07-20 01:30:00,011 INFO [48195] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron job started...
2021-07-20 01:30:00,012 INFO [48196] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 01:34:01,432 INFO [289616] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:69] [Scheduler]Spark streaming context product size: 0
2021-07-20 01:34:41,494 INFO [1474] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 22208 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 01:34:41,500 DEBUG [1480] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 01:34:41,501 INFO [1481] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:04:38,774 INFO [1015] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20304 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:04:38,777 DEBUG [1018] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:04:38,778 INFO [1019] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:04:51,036 INFO [13277] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 12.798 seconds (JVM running for 14.585)
2021-07-20 14:06:00,011 INFO [82252] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:39] Cron job started...
2021-07-20 14:06:00,012 INFO [82253] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:40] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:06:09,437 INFO [91678] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:70] [Scheduler]Spark streaming context product size: 0
2021-07-20 14:10:52,912 INFO [969 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 9124 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:10:52,915 DEBUG [972 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:10:52,916 INFO [973 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:11:04,228 INFO [12285] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.845 seconds (JVM running for 12.794)
2021-07-20 14:12:00,006 INFO [68063] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:12:00,007 INFO [68064] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:12:43,800 INFO [111857] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:70] [Scheduler]Spark streaming context product size: 0
2021-07-20 14:13:15,987 INFO [877 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20592 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:13:15,991 DEBUG [881 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:13:15,992 INFO [882 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:13:26,355 INFO [11245] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 10.865 seconds (JVM running for 11.707)
2021-07-20 14:13:28,685 INFO [13575] [s1-io-4] c.c.s.r.CassandraAsyncTemplateCustom [CassandraAsyncTemplateCustom.java:57] [createAsyncProduct]Write has been done successfully, entity: Product(id=862229008059441152, title=Alisha Solid Women's Cycling Shorts, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=null, variants=null, images=[ProductImage(id=null, position=1, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=null, position=2, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=null, position=3, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=null, position=4, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]), executionInfo: [com.datastax.oss.driver.internal.core.cql.DefaultExecutionInfo@4a702c15], rows: [com.datastax.oss.driver.internal.core.cql.DefaultRow@707d944e], wasApplied: true
2021-07-20 14:14:31,502 INFO [1007] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 3760 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:14:31,506 DEBUG [1011] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:14:31,506 INFO [1011] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:14:42,780 INFO [12285] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.82 seconds (JVM running for 12.749)
2021-07-20 14:16:00,007 INFO [89512] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:16:00,008 INFO [89513] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:16:20,379 ERROR [109884] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:76] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 14:16:53,115 INFO [984 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 2500 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:16:53,119 DEBUG [988 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:16:53,119 INFO [988 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:17:04,528 INFO [12397] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.944 seconds (JVM running for 12.878)
2021-07-20 14:18:00,009 INFO [67878] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:18:00,010 INFO [67879] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:19:03,087 ERROR [130956] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:76] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.spark.connector.types.TypeConversionException: Cannot convert object List({id: null, position: 1, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg}, {id: null, position: 2, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg}, {id: null, position: 3, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg}, {id: null, position: 4, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg}) of type class scala.collection.immutable.$colon$colon to com.datastax.spark.connector.japi.UDTValue.
	at com.datastax.spark.connector.types.TypeConverter$$anonfun$convert$1.apply(TypeConverter.scala:43)
	at com.datastax.spark.connector.japi.UDTValue$UDTValueConverter$$anonfun$convertPF$1.applyOrElse(UDTValue.scala:17)
	at com.datastax.spark.connector.types.TypeConverter$class.convert(TypeConverter.scala:41)
	at com.datastax.spark.connector.japi.UDTValue$UDTValueConverter$.com$datastax$spark$connector$types$NullableTypeConverter$$super$convert(UDTValue.scala:14)
	at com.datastax.spark.connector.types.NullableTypeConverter$class.convert(TypeConverter.scala:54)
	at com.datastax.spark.connector.japi.UDTValue$UDTValueConverter$.convert(UDTValue.scala:14)
	at com.datastax.spark.connector.japi.JavaGettableData$class._get(JavaGettableData.scala:32)
	at com.datastax.spark.connector.japi.JavaGettableData$class.getUDTValue(JavaGettableData.scala:117)
	at com.datastax.spark.connector.japi.CassandraRow.getUDTValue(CassandraRow.scala:6)
	at com.clover.storage.Scheduler.Scheduler$1.call(Scheduler.java:59)
	at com.clover.storage.Scheduler.Scheduler$1.call(Scheduler.java:48)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.spark.connector.types.TypeConversionException: Cannot convert object List({id: null, position: 1, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg}, {id: null, position: 2, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg}, {id: null, position: 3, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg}, {id: null, position: 4, product_id: null, variant_id: null, created_at: null, updated_at: null, src: http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg}) of type class scala.collection.immutable.$colon$colon to com.datastax.spark.connector.japi.UDTValue.
	at com.datastax.spark.connector.types.TypeConverter$$anonfun$convert$1.apply(TypeConverter.scala:43)
	at com.datastax.spark.connector.japi.UDTValue$UDTValueConverter$$anonfun$convertPF$1.applyOrElse(UDTValue.scala:17)
	at com.datastax.spark.connector.types.TypeConverter$class.convert(TypeConverter.scala:41)
	at com.datastax.spark.connector.japi.UDTValue$UDTValueConverter$.com$datastax$spark$connector$types$NullableTypeConverter$$super$convert(UDTValue.scala:14)
	at com.datastax.spark.connector.types.NullableTypeConverter$class.convert(TypeConverter.scala:54)
	at com.datastax.spark.connector.japi.UDTValue$UDTValueConverter$.convert(UDTValue.scala:14)
	at com.datastax.spark.connector.japi.JavaGettableData$class._get(JavaGettableData.scala:32)
	at com.datastax.spark.connector.japi.JavaGettableData$class.getUDTValue(JavaGettableData.scala:117)
	at com.datastax.spark.connector.japi.CassandraRow.getUDTValue(CassandraRow.scala:6)
	at com.clover.storage.Scheduler.Scheduler$1.call(Scheduler.java:59)
	at com.clover.storage.Scheduler.Scheduler$1.call(Scheduler.java:48)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1.apply(JavaPairRDD.scala:1040)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	... 3 common frames omitted
2021-07-20 14:21:14,294 INFO [1005] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 13356 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:21:14,298 DEBUG [1009] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:21:14,299 INFO [1010] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:21:25,460 INFO [12171] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.732 seconds (JVM running for 12.67)
2021-07-20 14:22:00,009 INFO [46720] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:22:00,009 INFO [46720] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:23:02,903 ERROR [109614] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [list<product_db_test.productimage> <-> com.datastax.driver.core.UDTValue]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:515)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:72)
	at com.datastax.driver.core.AbstractGettableByIndexData.getUDTValue(AbstractGettableByIndexData.java:293)
	at com.datastax.driver.core.AbstractGettableData.getUDTValue(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getUDTValue(AbstractGettableData.java:200)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:44)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:16)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 14:23:28,079 INFO [967 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 1680 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:23:28,082 DEBUG [970 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:23:28,082 INFO [970 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:23:39,179 INFO [12067] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.635 seconds (JVM running for 12.561)
2021-07-20 14:24:00,011 INFO [32899] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:24:00,011 INFO [32899] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:24:47,295 ERROR [80183] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 14:26:28,260 INFO [985 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 15956 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:26:28,265 DEBUG [990 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:26:28,265 INFO [990 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:26:39,334 INFO [12059] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.601 seconds (JVM running for 12.545)
2021-07-20 14:28:00,004 INFO [92729] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:28:00,005 INFO [92730] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:31:46,707 ERROR [319432] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 14:35:05,007 INFO [965 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 19104 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:35:05,010 DEBUG [968 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:35:05,010 INFO [968 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:35:28,261 INFO [982 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 952 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:35:28,265 DEBUG [986 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:35:28,265 INFO [986 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:35:39,526 INFO [12247] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.793 seconds (JVM running for 12.719)
2021-07-20 14:36:00,016 INFO [32737] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:36:00,016 INFO [32737] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:37:22,734 ERROR [115455] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 14:38:13,510 INFO [959 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 8840 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 14:38:13,514 DEBUG [963 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 14:38:13,514 INFO [963 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 14:38:24,215 INFO [11664] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.225 seconds (JVM running for 12.102)
2021-07-20 14:40:00,014 INFO [107463] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 14:40:00,015 INFO [107464] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 14:40:30,146 ERROR [137595] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 15:16:43,807 INFO [963 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 10480 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:16:43,810 DEBUG [966 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:16:43,810 INFO [966 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:16:55,005 INFO [12161] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.72 seconds (JVM running for 12.607)
2021-07-20 15:18:00,010 INFO [77166] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 15:18:00,010 INFO [77166] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 15:18:45,302 ERROR [122458] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productoption <-> com.clover.storage.model.ProductOption]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:77)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 15:23:22,832 INFO [978 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 17284 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:23:22,835 DEBUG [981 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:23:22,836 INFO [982 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:23:33,908 INFO [12054] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.608 seconds (JVM running for 12.499)
2021-07-20 15:24:00,007 INFO [38153] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 15:24:00,008 INFO [38154] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 15:26:06,254 ERROR [164400] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productoption <-> com.clover.storage.model.ProductOption]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:77)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 15:26:09,183 INFO [1093] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20320 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:26:09,186 DEBUG [1096] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:26:09,187 INFO [1097] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:26:20,380 INFO [12290] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.767 seconds (JVM running for 12.741)
2021-07-20 15:26:37,741 INFO [1001] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 17016 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:26:37,744 DEBUG [1004] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:26:37,745 INFO [1005] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:26:57,447 INFO [991 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 13072 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:26:57,451 DEBUG [995 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:26:57,451 INFO [995 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:27:08,616 INFO [12160] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.712 seconds (JVM running for 12.597)
2021-07-20 15:28:00,014 INFO [63558] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 15:28:00,015 INFO [63559] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 15:28:16,290 ERROR [79834] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 15:28:22,594 INFO [1121] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 21008 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:28:22,597 DEBUG [1124] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:28:22,597 INFO [1124] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:28:33,758 INFO [12285] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.771 seconds (JVM running for 12.756)
2021-07-20 15:30:00,004 INFO [98531] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 15:30:00,004 INFO [98531] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 15:30:30,234 ERROR [128761] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 15:31:38,720 INFO [980 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 9632 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:31:38,723 DEBUG [983 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:31:38,724 INFO [984 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:31:49,841 INFO [12101] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.657 seconds (JVM running for 12.545)
2021-07-20 15:32:00,013 INFO [22273] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 15:32:00,014 INFO [22274] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 15:32:23,244 ERROR [45504] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productoption <-> com.clover.storage.model.ProductOption]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:77)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 15:34:29,222 INFO [994 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 13020 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 15:34:29,226 DEBUG [998 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 15:34:29,226 INFO [998 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 15:34:44,276 INFO [16048] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 15.592 seconds (JVM running for 16.526)
2021-07-20 15:36:00,001 INFO [91773] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 15:36:00,001 INFO [91773] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:07:05,460 ERROR [9157232] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productoption <-> com.clover.storage.model.ProductOption]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:77)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:07:41,603 INFO [979 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 23864 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:07:41,607 DEBUG [983 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:07:41,607 INFO [983 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:07:52,726 INFO [12102] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.658 seconds (JVM running for 12.564)
2021-07-20 18:08:00,001 INFO [19377] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:08:00,002 INFO [19378] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:09:19,459 ERROR [98835] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productoption <-> com.clover.storage.model.ProductOption]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:77)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:09:31,874 INFO [967 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 24192 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:09:31,877 DEBUG [970 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:09:31,877 INFO [970 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:09:43,226 INFO [12319] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.871 seconds (JVM running for 12.764)
2021-07-20 18:10:00,009 INFO [29102] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:10:00,010 INFO [29103] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:11:14,451 ERROR [103544] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productoption <-> com.clover.storage.model.ProductOption]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:77)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:20:26,426 INFO [969 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 22108 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:20:26,430 DEBUG [973 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:20:26,430 INFO [973 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:20:37,474 INFO [12017] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.583 seconds (JVM running for 12.458)
2021-07-20 18:22:00,005 INFO [94548] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:22:00,005 INFO [94548] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:22:41,867 ERROR [136410] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:23:02,032 INFO [987 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 13860 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:23:02,035 DEBUG [990 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:23:02,036 INFO [991 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:23:13,167 INFO [12122] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.677 seconds (JVM running for 12.557)
2021-07-20 18:24:00,008 INFO [58963] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:24:00,009 INFO [58964] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:24:21,548 ERROR [80503] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 0.0 failed 1 times, most recent failure: Lost task 19.0 in stage 0.0 (TID 19, localhost, executor driver): com.datastax.driver.core.exceptions.CodecNotFoundException: Codec not found for requested operation: [product_db_test.productvariant <-> com.clover.storage.model.ProductVariant]
	at com.datastax.driver.core.CodecRegistry.notFound(CodecRegistry.java:806)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:636)
	at com.datastax.driver.core.CodecRegistry.findCodec(CodecRegistry.java:607)
	at com.datastax.driver.core.CodecRegistry.maybeCreateCodec(CodecRegistry.java:668)
	at com.datastax.driver.core.CodecRegistry.createCodec(CodecRegistry.java:635)
	at com.datastax.driver.core.CodecRegistry.access$500(CodecRegistry.java:165)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:277)
	at com.datastax.driver.core.CodecRegistry$TypeCodecCacheLoader.load(CodecRegistry.java:261)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3708)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2416)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2299)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2212)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4147)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4151)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:5140)
	at com.datastax.driver.core.CodecRegistry.lookupCodec(CodecRegistry.java:571)
	at com.datastax.driver.core.CodecRegistry.codecFor(CodecRegistry.java:534)
	at com.datastax.driver.core.AbstractGettableByIndexData.codecFor(AbstractGettableByIndexData.java:76)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:253)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableByIndexData.getList(AbstractGettableByIndexData.java:244)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:29)
	at com.datastax.driver.core.AbstractGettableData.getList(AbstractGettableData.java:164)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:79)
	at com.clover.storage.model.ProductRowReader.read(ProductRowReader.java:21)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD$$anonfun$15.apply(CassandraTableScanRDD.scala:346)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:445)
	at com.datastax.spark.connector.util.CountingIterator.next(CountingIterator.scala:16)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.util.CountingIterator.foreach(CountingIterator.scala:4)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at com.datastax.spark.connector.util.CountingIterator.to(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
	at com.datastax.spark.connector.util.CountingIterator.toBuffer(CountingIterator.scala:4)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
	at com.datastax.spark.connector.util.CountingIterator.toArray(CountingIterator.scala:4)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2107)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:24:55,378 INFO [982 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 18616 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:24:55,381 DEBUG [985 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:24:55,381 INFO [985 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:25:06,461 INFO [12065] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.623 seconds (JVM running for 12.528)
2021-07-20 18:26:00,014 INFO [65618] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:26:00,015 INFO [65619] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:31:42,288 INFO [998 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 18044 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:31:42,292 DEBUG [1002] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:31:42,293 INFO [1003] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:31:53,440 INFO [12150] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.707 seconds (JVM running for 12.622)
2021-07-20 18:32:00,011 INFO [18721] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:32:00,012 INFO [18722] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:33:02,860 ERROR [81570] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:35:04,323 INFO [981 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 19804 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:35:04,326 DEBUG [984 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:35:04,327 INFO [985 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:35:15,401 INFO [12059] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.618 seconds (JVM running for 12.508)
2021-07-20 18:36:00,005 INFO [56663] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:36:00,006 INFO [56664] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:37:56,355 ERROR [173013] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:38:30,171 INFO [990 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 16356 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:38:30,175 DEBUG [994 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:38:30,175 INFO [994 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:38:41,287 INFO [12106] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.649 seconds (JVM running for 12.566)
2021-07-20 18:40:00,006 INFO [90825] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:40:00,007 INFO [90826] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 18:40:11,749 ERROR [102568] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:83] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:954)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:952)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:952)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2164)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2077)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:214)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 18:40:24,479 INFO [1017] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 23336 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 18:40:24,482 DEBUG [1020] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 18:40:24,483 INFO [1021] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 18:40:35,592 INFO [12130] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.673 seconds (JVM running for 12.589)
2021-07-20 18:42:00,009 INFO [96547] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 18:42:00,010 INFO [96548] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:13:15,641 INFO [1087] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 2204 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:13:15,645 DEBUG [1091] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:13:15,645 INFO [1091] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:13:27,204 INFO [12650] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 12.172 seconds (JVM running for 13.111)
2021-07-20 20:14:00,016 INFO [45462] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:41] Cron job started...
2021-07-20 20:14:00,017 INFO [45463] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:21:01,894 ERROR [467340] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:57] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 20:21:17,657 INFO [975 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20992 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:21:17,661 DEBUG [979 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:21:17,661 INFO [979 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:21:28,776 INFO [12094] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.65 seconds (JVM running for 12.53)
2021-07-20 20:22:00,010 INFO [43328] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:42] Cron job started...
2021-07-20 20:22:00,010 INFO [43328] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:43] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:24:18,043 ERROR [181361] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:58] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 20:25:56,640 INFO [1193] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 23004 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:25:56,643 DEBUG [1196] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:25:56,644 INFO [1197] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:26:07,744 INFO [12297] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.806 seconds (JVM running for 12.741)
2021-07-20 20:28:00,013 INFO [124566] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:44] Cron job started...
2021-07-20 20:28:00,014 INFO [124567] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:45] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:28:18,008 ERROR [142561] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 20:29:23,284 INFO [1069] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20420 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:29:23,288 DEBUG [1073] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:29:23,288 INFO [1073] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:29:34,566 INFO [12351] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.895 seconds (JVM running for 12.782)
2021-07-20 20:30:00,012 INFO [37797] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:45] Cron job started...
2021-07-20 20:30:00,012 INFO [37797] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:46] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:33:47,462 ERROR [265247] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:61] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:54)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 20:34:01,614 INFO [993 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 21004 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:34:01,617 DEBUG [996 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:34:01,618 INFO [997 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:34:12,885 INFO [12264] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.823 seconds (JVM running for 12.772)
2021-07-20 20:36:00,013 INFO [119392] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:46] Cron job started...
2021-07-20 20:36:00,014 INFO [119393] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:36:30,107 ERROR [149486] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:62] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:55)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 20:36:35,725 INFO [1018] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 19204 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:36:35,728 DEBUG [1021] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:36:35,729 INFO [1022] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:36:46,963 INFO [12256] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.787 seconds (JVM running for 12.701)
2021-07-20 20:38:00,007 INFO [85300] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:46] Cron job started...
2021-07-20 20:38:00,008 INFO [85301] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:38:12,029 ERROR [97322] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:61] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:54)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 20:41:46,731 INFO [972 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 21988 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:41:46,735 DEBUG [976 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:41:46,735 INFO [976 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:41:57,881 INFO [12122] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.679 seconds (JVM running for 12.565)
2021-07-20 20:42:00,014 INFO [14255] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:46] Cron job started...
2021-07-20 20:42:00,015 INFO [14256] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:47] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:47:31,760 ERROR [346001] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:67] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Task not serializable
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:416)
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:406)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:163)
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2332)
	at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:393)
	at org.apache.spark.rdd.RDD$$anonfun$map$1.apply(RDD.scala:392)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.map(RDD.scala:392)
	at org.apache.spark.api.java.JavaRDDLike$class.map(JavaRDDLike.scala:93)
	at org.apache.spark.api.java.AbstractJavaRDDLike.map(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:53)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.NotSerializableException: com.clover.storage.util.ElasticSearchUtil
Serialization stack:
	- object not serializable (class: com.clover.storage.util.ElasticSearchUtil, value: com.clover.storage.util.ElasticSearchUtil@cda144a)
	- field (class: com.clover.storage.Scheduler.Scheduler, name: elasticSearchUtil, type: class com.clover.storage.util.ElasticSearchUtil)
	- object (class com.clover.storage.Scheduler.Scheduler, com.clover.storage.Scheduler.Scheduler@2b82018)
	- field (class: com.clover.storage.Scheduler.Scheduler$1, name: this$0, type: class com.clover.storage.Scheduler.Scheduler)
	- object (class com.clover.storage.Scheduler.Scheduler$1, com.clover.storage.Scheduler.Scheduler$1@54113606)
	- field (class: org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, name: fun$1, type: interface org.apache.spark.api.java.function.Function)
	- object (class org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, <function1>)
	at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:413)
	... 27 common frames omitted
2021-07-20 20:48:13,089 INFO [1042] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 20968 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:48:13,092 DEBUG [1045] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:48:13,092 INFO [1045] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:48:24,353 INFO [12306] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.828 seconds (JVM running for 12.738)
2021-07-20 20:50:00,012 INFO [107965] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron job started...
2021-07-20 20:50:00,013 INFO [107966] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:51] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:50:26,730 ERROR [134683] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:81] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Task not serializable
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:416)
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:406)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:163)
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2332)
	at org.apache.spark.rdd.RDD$$anonfun$keyBy$1.apply(RDD.scala:1578)
	at org.apache.spark.rdd.RDD$$anonfun$keyBy$1.apply(RDD.scala:1577)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.keyBy(RDD.scala:1577)
	at org.apache.spark.api.java.JavaRDDLike$class.keyBy(JavaRDDLike.scala:574)
	at org.apache.spark.api.java.AbstractJavaRDDLike.keyBy(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.NotSerializableException: com.clover.storage.util.ElasticSearchUtil
Serialization stack:
	- object not serializable (class: com.clover.storage.util.ElasticSearchUtil, value: com.clover.storage.util.ElasticSearchUtil@46fdfaeb)
	- field (class: com.clover.storage.Scheduler.Scheduler, name: elasticSearchUtil, type: class com.clover.storage.util.ElasticSearchUtil)
	- object (class com.clover.storage.Scheduler.Scheduler, com.clover.storage.Scheduler.Scheduler@7df5549e)
	- field (class: com.clover.storage.Scheduler.Scheduler$1, name: this$0, type: class com.clover.storage.Scheduler.Scheduler)
	- object (class com.clover.storage.Scheduler.Scheduler$1, com.clover.storage.Scheduler.Scheduler$1@318d5fd7)
	- field (class: org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, name: fun$1, type: interface org.apache.spark.api.java.function.Function)
	- object (class org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction$1, <function1>)
	at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:40)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:413)
	... 27 common frames omitted
2021-07-20 20:50:57,273 INFO [981 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 15480 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 20:50:57,276 DEBUG [984 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 20:50:57,276 INFO [984 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 20:51:08,520 INFO [12228] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.789 seconds (JVM running for 12.674)
2021-07-20 20:52:00,002 INFO [63710] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron job started...
2021-07-20 20:52:00,003 INFO [63711] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:51] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 20:52:49,531 ERROR [113239] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:81] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- field (class: scala.Tuple2, name: _2, type: class java.lang.Object)
	- object (class scala.Tuple2, (862229008059441152,Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)])))
	- element of array (index: 0)
	- array (class [Lscala.Tuple2;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 21:55:33,303 INFO [1215] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 18308 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 21:55:33,306 DEBUG [1218] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 21:55:33,307 INFO [1219] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 21:55:45,112 INFO [13024] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 12.522 seconds (JVM running for 13.551)
2021-07-20 21:56:00,006 INFO [27918] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron job started...
2021-07-20 21:56:00,008 INFO [27920] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:51] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 21:56:59,454 ERROR [87366] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:81] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- field (class: scala.Tuple2, name: _2, type: class java.lang.Object)
	- object (class scala.Tuple2, (862229008059441152,Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)])))
	- element of array (index: 0)
	- array (class [Lscala.Tuple2;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:69)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 22:01:12,677 INFO [989 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 14272 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 22:01:12,681 DEBUG [993 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 22:01:12,681 INFO [993 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 22:01:23,805 INFO [12117] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.666 seconds (JVM running for 12.578)
2021-07-20 22:02:00,014 INFO [48326] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:02:00,015 INFO [48327] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:06:40,517 ERROR [328829] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:80] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.Product
Serialization stack:
	- object not serializable (class: com.clover.storage.model.Product, value: Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 22:06:47,548 INFO [985 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 14576 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 22:06:47,551 DEBUG [988 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 22:06:47,552 INFO [989 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 22:06:58,666 INFO [12103] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.654 seconds (JVM running for 12.537)
2021-07-20 22:08:00,010 INFO [73447] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:08:00,011 INFO [73448] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:08:53,230 ERROR [126667] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:80] [Scheduler]Exception while starting scheduler for reading cassandra table 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 19.0 in stage 0.0 (TID 19) had a not serializable result: com.clover.storage.model.ProductImage
Serialization stack:
	- object not serializable (class: com.clover.storage.model.ProductImage, value: ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg))
	- writeObject data (class: java.util.ArrayList)
	- object (class java.util.ArrayList, [ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)])
	- field (class: com.clover.storage.model.Product, name: images, type: interface java.util.List)
	- object (class com.clover.storage.model.Product, Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]))
	- element of array (index: 0)
	- array (class [Lcom.clover.storage.model.Product;, size 1)
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:73)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 22:09:13,504 INFO [977 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 23180 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 22:09:13,508 DEBUG [981 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 22:09:13,508 INFO [981 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 22:09:24,564 INFO [12037] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.593 seconds (JVM running for 12.475)
2021-07-20 22:10:00,002 INFO [47475] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:10:00,003 INFO [47476] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:10:34,164 INFO [989 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 12432 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 22:10:34,168 DEBUG [993 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 22:10:34,168 INFO [993 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 22:10:45,259 INFO [12084] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 11.628 seconds (JVM running for 12.523)
2021-07-20 22:12:00,003 INFO [86828] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:12:00,004 INFO [86829] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:12:06,929 INFO [93754] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:74] [Scheduler]Spark streaming context product size: 1
2021-07-20 22:12:17,565 INFO [104390] [Async-Clover-1] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:42] [postHttpClient]Post http client call of URI: http://localhost:8092/api/v1/index, payload: [Product(id=862229008059441152, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=[], variants=[], images=[ProductImage(id=0, position=1, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=0, position=2, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=0, position=3, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=0, position=4, product_id=0, variant_id=0, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)])]
2021-07-20 22:47:21,933 INFO [868 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 18000 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 22:47:21,935 DEBUG [870 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 22:47:21,936 INFO [871 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 22:47:44,338 INFO [23273] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 22.879 seconds (JVM running for 23.687)
2021-07-20 22:48:00,011 INFO [38946] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:48:00,012 INFO [38947] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:48:02,613 INFO [41548] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 22:48:57,481 INFO [96416] [s1-io-4] c.c.s.r.CassandraAsyncTemplateCustom [CassandraAsyncTemplateCustom.java:57] [createAsyncProduct]Write has been done successfully, entity: Product(id=862229008059441152, title=Alisha Solid Women's Cycling Shorts, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=null, updated_at=null, vendor=Alisha, status=ACTIVE, options=null, variants=null, images=[ProductImage(id=null, position=1, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=null, position=2, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=null, position=3, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=null, position=4, product_id=null, variant_id=null, created_at=null, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]), executionInfo: [com.datastax.oss.driver.internal.core.cql.DefaultExecutionInfo@26ea780c], rows: [com.datastax.oss.driver.internal.core.cql.DefaultRow@1b33a5ac], wasApplied: true
2021-07-20 22:50:00,014 INFO [158949] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:50:00,014 INFO [158949] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:50:00,110 ERROR [159045] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:67] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Couldn't find table product_tbl_test or keyspace product_db_test - Found similar keyspaces and tables:
product_keyspace.product_table
	at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:358)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:50)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:137)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:263)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 22:52:00,002 INFO [278937] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:52:00,002 INFO [278937] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:52:00,074 ERROR [279009] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:67] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Couldn't find table product_tbl_test or keyspace product_db_test - Found similar keyspaces and tables:
product_keyspace.product_table
	at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:358)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:50)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:137)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:263)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 22:54:02,387 INFO [814 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 15020 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 22:54:02,390 DEBUG [817 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 22:54:02,391 INFO [818 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 22:54:20,473 INFO [18900] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 18.542 seconds (JVM running for 19.31)
2021-07-20 22:56:00,006 INFO [118433] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:56:00,007 INFO [118434] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:56:02,624 INFO [121051] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 22:58:00,002 INFO [238429] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 22:58:00,002 INFO [238429] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 22:58:00,373 INFO [238800] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 23:00:00,010 INFO [358437] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:00:00,010 INFO [358437] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:00:00,332 INFO [358759] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 23:02:00,011 INFO [478438] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:02:00,012 INFO [478439] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:02:00,335 INFO [478762] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 23:04:00,012 INFO [598439] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:04:00,013 INFO [598440] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:04:00,610 INFO [599037] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 23:05:24,655 INFO [683082] [s1-io-4] c.c.s.r.CassandraAsyncTemplateCustom [CassandraAsyncTemplateCustom.java:57] [createAsyncProduct]Write has been done successfully, entity: Product(id=867093664471867392, title=FabHomeDecor Fabric Double Sofa Bed, description=FabHomeDecor Fabric Double Sofa Bed (Finish Color - Leatherette Black Mechanism Type - Pull Out) Price: Rs. 22,646, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, vendor=FabHomeDecor, status=ACTIVE, options=[ProductOption(id=867093664589307904, product_id=867093664471867392, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867093664580919296, product_id=867093664471867392, sku=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867093664509616128, position=1, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-1100x1100-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664513810432, position=2, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664518004736, position=3, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3genfxkqvuv.jpeg), ProductImage(id=867093664522199040, position=4, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img5a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3ge2sfeczef.jpeg)]), executionInfo: [com.datastax.oss.driver.internal.core.cql.DefaultExecutionInfo@16520f63], rows: [com.datastax.oss.driver.internal.core.cql.DefaultRow@1cbaaa8c], wasApplied: true
2021-07-20 23:06:00,009 INFO [718436] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:06:00,009 INFO [718436] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:06:00,324 INFO [718751] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 1
2021-07-20 23:06:00,329 INFO [718756] [Async-Clover-1] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:42] [postHttpClient]Post http client call of URI: http://localhost:8092/api/v1/index, payload: [Product(id=867093664471867392, title=null, description=FabHomeDecor Fabric Double Sofa Bed (Finish Color - Leatherette Black Mechanism Type - Pull Out) Price: Rs. 22,646, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, vendor=FabHomeDecor, status=ACTIVE, options=[ProductOption(id=867093664589307904, product_id=867093664471867392, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867093664580919296, product_id=867093664471867392, sku=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867093664509616128, position=1, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-1100x1100-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664513810432, position=2, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664518004736, position=3, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3genfxkqvuv.jpeg), ProductImage(id=867093664522199040, position=4, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img5a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3ge2sfeczef.jpeg)])]
2021-07-20 23:06:04,486 ERROR [722913] [Async-Clover-1] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:74] [postHttpClient]Exception while invoking http post call of URI: http://localhost:8092/api/v1/index
org.apache.http.conn.HttpHostConnectException: Connect to localhost:8092 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.clover.storage.util.CloverHttpClientUtil.postHttpClient(CloverHttpClientUtil.java:55)
	at com.clover.storage.util.CloverHttpClientUtil$$FastClassBySpringCGLIB$$7fe9ece7.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)
	at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115)
	at org.springframework.aop.interceptor.AsyncExecutionAspectSupport.lambda$doSubmit$3(AsyncExecutionAspectSupport.java:276)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:81)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:476)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:218)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:200)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:162)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 21 common frames omitted
2021-07-20 23:06:04,487 INFO [722914] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:64] [Scheduler]Elasticsearch save result status: null
2021-07-20 23:06:46,046 INFO [764473] [s1-io-4] c.c.s.r.CassandraAsyncTemplateCustom [CassandraAsyncTemplateCustom.java:57] [createAsyncProduct]Write has been done successfully, entity: Product(id=867097646875435008, title=Alisha Solid Women's Cycling Shorts, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, vendor=Alisha, status=ACTIVE, options=[ProductOption(id=867097646908989440, product_id=867097646875435008, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867097646904795136, product_id=867097646875435008, sku=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867097646892212224, position=1, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=867097646892212225, position=2, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=867097646896406528, position=3, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=867097646900600832, position=4, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]), executionInfo: [com.datastax.oss.driver.internal.core.cql.DefaultExecutionInfo@7f0f44a9], rows: [com.datastax.oss.driver.internal.core.cql.DefaultRow@447a0647], wasApplied: true
2021-07-20 23:08:00,011 INFO [838438] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:08:00,011 INFO [838438] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:08:00,314 INFO [838741] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 2
2021-07-20 23:08:00,315 INFO [838742] [Async-Clover-2] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:42] [postHttpClient]Post http client call of URI: http://localhost:8092/api/v1/index, payload: [Product(id=867097646875435008, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, vendor=Alisha, status=ACTIVE, options=[ProductOption(id=867097646908989440, product_id=867097646875435008, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867097646904795136, product_id=867097646875435008, sku=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867097646892212224, position=1, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=867097646892212225, position=2, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=867097646896406528, position=3, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=867097646900600832, position=4, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]), Product(id=867093664471867392, title=null, description=FabHomeDecor Fabric Double Sofa Bed (Finish Color - Leatherette Black Mechanism Type - Pull Out) Price: Rs. 22,646, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, vendor=FabHomeDecor, status=ACTIVE, options=[ProductOption(id=867093664589307904, product_id=867093664471867392, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867093664580919296, product_id=867093664471867392, sku=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867093664509616128, position=1, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-1100x1100-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664513810432, position=2, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664518004736, position=3, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3genfxkqvuv.jpeg), ProductImage(id=867093664522199040, position=4, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img5a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3ge2sfeczef.jpeg)])]
2021-07-20 23:08:04,373 ERROR [842800] [Async-Clover-2] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:74] [postHttpClient]Exception while invoking http post call of URI: http://localhost:8092/api/v1/index
org.apache.http.conn.HttpHostConnectException: Connect to localhost:8092 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.clover.storage.util.CloverHttpClientUtil.postHttpClient(CloverHttpClientUtil.java:55)
	at com.clover.storage.util.CloverHttpClientUtil$$FastClassBySpringCGLIB$$7fe9ece7.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)
	at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115)
	at org.springframework.aop.interceptor.AsyncExecutionAspectSupport.lambda$doSubmit$3(AsyncExecutionAspectSupport.java:276)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:81)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:476)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:218)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:200)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:162)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 21 common frames omitted
2021-07-20 23:08:04,374 INFO [842801] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:64] [Scheduler]Elasticsearch save result status: null
2021-07-20 23:10:00,006 INFO [958433] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:10:00,006 INFO [958433] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:10:00,082 ERROR [958509] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:67] [Scheduler]Exception while starting scheduler for reading cassandra table 
java.io.IOException: Couldn't find table product_tbl_test or keyspace product_db_test - Found similar keyspaces and tables:
product_keyspace.product_table
	at com.datastax.spark.connector.cql.Schema$.tableFromCassandra(Schema.scala:358)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.tableDef(CassandraTableRowReaderProvider.scala:50)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef$lzycompute(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.tableDef(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableRowReaderProvider$class.verify(CassandraTableRowReaderProvider.scala:137)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.verify(CassandraTableScanRDD.scala:63)
	at com.datastax.spark.connector.rdd.CassandraTableScanRDD.getPartitions(CassandraTableScanRDD.scala:263)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.api.java.JavaRDDLike$class.collect(JavaRDDLike.scala:361)
	at org.apache.spark.api.java.AbstractJavaRDDLike.collect(JavaRDDLike.scala:45)
	at com.clover.storage.Scheduler.Scheduler.startCassandraStreamToElasticsearch(Scheduler.java:59)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.scheduling.support.ScheduledMethodRunnable.run(ScheduledMethodRunnable.java:84)
	at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)
	at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:95)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-07-20 23:11:15,573 INFO [893 ] [main] c.c.s.m.App [StartupInfoLogger.java:55] Starting App using Java 1.8.0_291 on DESKTOP-1SBRRM8 with PID 18136 (D:\Projects\Clover\CassandraStorageService\target\classes started by Priyash in D:\Projects\Clover\CassandraStorageService)
2021-07-20 23:11:15,576 DEBUG [896 ] [main] c.c.s.m.App [StartupInfoLogger.java:56] Running with Spring Boot v2.5.1, Spring v5.3.8
2021-07-20 23:11:15,577 INFO [897 ] [main] c.c.s.m.App [SpringApplication.java:659] No active profile set, falling back to default profiles: default
2021-07-20 23:11:35,519 INFO [20839] [main] c.c.s.m.App [StartupInfoLogger.java:61] Started App in 20.412 seconds (JVM running for 21.53)
2021-07-20 23:12:00,015 INFO [45335] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:12:00,015 INFO [45335] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:12:03,500 INFO [48820] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 0
2021-07-20 23:13:24,493 INFO [129813] [s1-io-4] c.c.s.r.CassandraAsyncTemplateCustom [CassandraAsyncTemplateCustom.java:57] [createAsyncProduct]Write has been done successfully, entity: Product(id=867093664471867392, title=FabHomeDecor Fabric Double Sofa Bed, description=FabHomeDecor Fabric Double Sofa Bed (Finish Color - Leatherette Black Mechanism Type - Pull Out) Price: Rs. 22,646, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, vendor=FabHomeDecor, status=ACTIVE, options=[ProductOption(id=867093664589307904, product_id=867093664471867392, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867093664580919296, product_id=867093664471867392, sku=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867093664509616128, position=1, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-1100x1100-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664513810432, position=2, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664518004736, position=3, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3genfxkqvuv.jpeg), ProductImage(id=867093664522199040, position=4, product_id=867093664471867392, variant_id=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, src=http://img5a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3ge2sfeczef.jpeg)]), executionInfo: [com.datastax.oss.driver.internal.core.cql.DefaultExecutionInfo@7fc7fd04], rows: [com.datastax.oss.driver.internal.core.cql.DefaultRow@11992ec3], wasApplied: true
2021-07-20 23:13:24,516 INFO [129836] [s1-io-4] c.c.s.r.CassandraAsyncTemplateCustom [CassandraAsyncTemplateCustom.java:57] [createAsyncProduct]Write has been done successfully, entity: Product(id=867097646875435008, title=Alisha Solid Women's Cycling Shorts, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, vendor=Alisha, status=ACTIVE, options=[ProductOption(id=867097646908989440, product_id=867097646875435008, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867097646904795136, product_id=867097646875435008, sku=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867097646892212224, position=1, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=867097646892212225, position=2, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=867097646896406528, position=3, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=867097646900600832, position=4, product_id=867097646875435008, variant_id=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]), executionInfo: [com.datastax.oss.driver.internal.core.cql.DefaultExecutionInfo@2e77eb3d], rows: [com.datastax.oss.driver.internal.core.cql.DefaultRow@472d6e30], wasApplied: true
2021-07-20 23:14:00,013 INFO [165333] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:49] Cron job started...
2021-07-20 23:14:00,013 INFO [165333] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:50] Cron expression: '0 0/2 * 1/1 * ?'
2021-07-20 23:14:00,373 INFO [165693] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:60] [Scheduler]Spark streaming context product size: 2
2021-07-20 23:14:00,379 INFO [165699] [Async-Clover-1] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:42] [postHttpClient]Post http client call of URI: http://localhost:8092/api/v1/index, payload: [Product(id=867097646875435008, title=null, description=Key Features of Alisha Solid Women's Cycling Shorts Cotton Lycra Navy, Red, Navy,Specifications of Alisha Solid Women's Cycling Shorts Shorts Details Number of Contents in Sales Package Pack of 3 Fabric Cotton Lycra Type Cycling Shorts General Details Pattern Solid Ideal For Women's Fabric Care Gentle Machine Wash in Lukewarm Water, Do Not Bleach Additional Details Style Code ALTHT_3P_21 In the Box 3 shorts, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, vendor=Alisha, status=ACTIVE, options=[ProductOption(id=867097646908989440, product_id=867097646875435008, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867097646904795136, product_id=867097646875435008, sku=null, created_at=2021-07-20T17:36:28+0000, updated_at=2021-07-20T17:36:28+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867097646892212224, position=1, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/u/4/a/altht-3p-21-alisha-38-original-imaeh2d5vm5zbtgg.jpeg), ProductImage(id=867097646892212225, position=2, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5kbufss6n.jpeg), ProductImage(id=867097646896406528, position=3, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/p/j/z/altght4p-26-alisha-38-original-imaeh2d5npdybzyt.jpeg), ProductImage(id=867097646900600832, position=4, product_id=867097646875435008, variant_id=0, created_at=2021-07-20T17:36:28+0000, updated_at=null, src=http://img5a.flixcart.com/image/short/z/j/7/altght-7-alisha-38-original-imaeh2d5jsz2ghd6.jpeg)]), Product(id=867093664471867392, title=null, description=FabHomeDecor Fabric Double Sofa Bed (Finish Color - Leatherette Black Mechanism Type - Pull Out) Price: Rs. 22,646, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, vendor=FabHomeDecor, status=ACTIVE, options=[ProductOption(id=867093664589307904, product_id=867093664471867392, name=default option title, values=[default values])], variants=[ProductVariant(title=default_title, id=867093664580919296, product_id=867093664471867392, sku=null, created_at=2021-07-20T17:20:39+0000, updated_at=2021-07-20T17:20:39+0000, price=0.0, option1=null, option2=null, option3=null)], images=[ProductImage(id=867093664509616128, position=1, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-1100x1100-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664513810432, position=2, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3gemjjcg9ta.jpeg), ProductImage(id=867093664518004736, position=3, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img6a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3genfxkqvuv.jpeg), ProductImage(id=867093664522199040, position=4, product_id=867093664471867392, variant_id=0, created_at=2021-07-20T17:20:39+0000, updated_at=null, src=http://img5a.flixcart.com/image/sofa-bed/j/f/y/fhd112-double-foam-fabhomedecor-leatherette-black-leatherette-original-imaeh3ge2sfeczef.jpeg)])]
2021-07-20 23:14:04,539 ERROR [169859] [Async-Clover-1] c.c.s.u.CloverHttpClientUtil [CloverHttpClientUtil.java:74] [postHttpClient]Exception while invoking http post call of URI: http://localhost:8092/api/v1/index
org.apache.http.conn.HttpHostConnectException: Connect to localhost:8092 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.clover.storage.util.CloverHttpClientUtil.postHttpClient(CloverHttpClientUtil.java:55)
	at com.clover.storage.util.CloverHttpClientUtil$$FastClassBySpringCGLIB$$7fe9ece7.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:779)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:750)
	at org.springframework.aop.interceptor.AsyncExecutionInterceptor.lambda$invoke$0(AsyncExecutionInterceptor.java:115)
	at org.springframework.aop.interceptor.AsyncExecutionAspectSupport.lambda$doSubmit$3(AsyncExecutionAspectSupport.java:276)
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:81)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:476)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:218)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:200)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:162)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:394)
	at java.net.Socket.connect(Socket.java:606)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 21 common frames omitted
2021-07-20 23:14:04,540 INFO [169860] [scheduling-1] c.c.s.S.Scheduler [Scheduler.java:64] [Scheduler]Elasticsearch save result status: null
